{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from joblib import load\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentralMontneyRatePred:\n",
    "    def __init__(self, static_inputs, static_input_keys, prod_hist=None, shut_list=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        static_inputs (dict): A dictionary containing the static inputs provided by the user.\n",
    "        prod_hist (array): A 2D numpy array representing historical production data with shape (n_timesteps, 3).\n",
    "        shut_list (list): A list of indices representing shut-in periods (optional).\n",
    "        \"\"\"\n",
    "        # Define the keys for peak input\n",
    "        self.peak_input_keys = static_input_keys\n",
    "        self.gbr_model_p = self._load_gbr_model()\n",
    "        self.AI_model = self.load_model()\n",
    "        self.static_inputs = self.convert_static_inputs(static_inputs)\n",
    "        self.prod_hist = self._pad_prod_hist(prod_hist)  # Pad or initialize prod_hist to (60, 3)\n",
    "        self.shut_ins = self._convert_shut_list(shut_list)  # Convert or initialize shut_list to (60, 1)\n",
    "        self.hist_len = len(prod_hist) if prod_hist is not None else 0  # Determine hist_len\n",
    "        self.dynamic_df = None  # Dynamic inputs generated from static inputs\n",
    "        self.scalers = self._load_scalers()\n",
    "\n",
    "        # Predict PeakTime and PeakRate if they are not provided\n",
    "        if 'PeakTime' not in self.static_inputs or 'PeakRate' not in self.static_inputs:\n",
    "            self.predict_peak()\n",
    "\n",
    "    def _pad_prod_hist(self, prod_hist):\n",
    "        if prod_hist is None:\n",
    "            return np.zeros((60, 3))  # Default to zeros if no production history is provided\n",
    "\n",
    "        padded_hist = np.zeros((60, 3))  # Initialize a (60, 3) array with zeros\n",
    "        length = min(len(prod_hist), 60)  # Determine how much of prod_hist can be used\n",
    "        padded_hist[:length, :] = prod_hist[:length, :]  # Fill with available production history\n",
    "        print(padded_hist)\n",
    "        return padded_hist\n",
    "\n",
    "    def _convert_shut_list(self, shut_list):\n",
    "        shut_ins = np.zeros((60, 1))  # Initialize a (60, 1) array with zeros\n",
    "        if shut_list is not None:\n",
    "            for index in shut_list:\n",
    "                if 0 <= index < 60:  # Ensure the index is within bounds\n",
    "                    shut_ins[index, 0] = 1\n",
    "        return shut_ins\n",
    "        \n",
    "    def _load_gbr_model(self):\n",
    "        try:\n",
    "            return load('c:\\\\Users\\\\ziming4\\\\OneDrive - University of Alberta\\\\Porject_OPI\\\\WebPrototype0823\\\\OpenPredictionInterface\\\\backend\\\\app/integrations/Montney/multi_gbr_regressor_peak.joblib')\n",
    "        except Exception as e:\n",
    "            raise FileNotFoundError(\"GBR model could not be loaded. Ensure the file path is correct.\") from e\n",
    "\n",
    "    def load_model(self):\n",
    "        mask_special_val = -1e9\n",
    "        threshold_active = 0\n",
    "\n",
    "        def thresholded_tanh(x, threshold=threshold_active):\n",
    "            thresholds = tf.constant(threshold, dtype=x.dtype)\n",
    "            thresholds = tf.reshape(thresholds, (1, 1, -1))\n",
    "            tanh_x = tf.tanh(x)\n",
    "            adjusted_tanh = (tanh_x + 1) / 2 * (1 - thresholds) + thresholds  # Scales and shifts the output\n",
    "            return adjusted_tanh\n",
    "\n",
    "        def masked_loss_function(y_true, y_pred):\n",
    "            mask = K.cast(K.not_equal(y_true, mask_special_val), K.floatx())\n",
    "            y_true_masked = y_true * mask\n",
    "            y_pred_masked = y_pred * mask\n",
    "            loss = K.mean(K.square(y_pred_masked - y_true_masked), axis=-1)\n",
    "            return loss\n",
    "\n",
    "        # Load the model with the registered custom objects\n",
    "        try:\n",
    "            model = keras.models.load_model(\n",
    "                'c:\\\\Users\\\\ziming4\\\\OneDrive - University of Alberta\\\\Porject_OPI\\\\WebPrototype0823\\\\OpenPredictionInterface\\\\backend\\\\app/integrations/Montney/MED_DUDS_denoise_1024.keras',\n",
    "                custom_objects={\n",
    "                    'masked_loss_function': masked_loss_function,\n",
    "                    'thresholded_tanh': thresholded_tanh\n",
    "                }\n",
    "            )\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error details: {e}\")\n",
    "            raise FileNotFoundError(\"AI model could not be loaded.\") from e\n",
    "\n",
    "    def _load_scalers(self):\n",
    "        try:\n",
    "            scalers = {}\n",
    "            scaler_paths = ['scaler_encoder.pkl', 'scaler_decoder_D.pkl', 'scaler_decoder_S.pkl', 'scaler_y_pred_3phase.pkl']\n",
    "            scaler_names = ['scaler_encoder', 'scaler_decoder_D', 'scaler_decoder_S', 'scaler_y_pred']\n",
    "\n",
    "            for name, path in zip(scaler_names, scaler_paths):\n",
    "                with open(Path('c:\\\\Users\\\\ziming4\\\\OneDrive - University of Alberta\\\\Porject_OPI\\\\WebPrototype0823\\\\OpenPredictionInterface\\\\backend\\\\app/integrations/Montney/ml_model_scalers') / path, 'rb') as file:\n",
    "                    scalers[name] = pickle.load(file)\n",
    "            return scalers\n",
    "\n",
    "        except Exception as e:\n",
    "            raise FileNotFoundError(\"One or more scaler files could not be loaded. Ensure the file paths are correct.\") from e\n",
    "        \n",
    "    def classify_and_update_feature(self, feature_name: str, feature_dict: dict, encoding_dict: dict) -> dict:\n",
    "        \"\"\"Classifies and updates a feature using the given encoding dictionary.\"\"\"\n",
    "        updated_features = feature_dict.copy()\n",
    "        feature_value = updated_features.get(feature_name, \"\").upper()\n",
    "\n",
    "        if feature_name in encoding_dict:\n",
    "            if feature_value in encoding_dict[feature_name]:\n",
    "                updated_features[feature_name] = encoding_dict[feature_name][feature_value]\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Value '{feature_value}' not found in label encodings for '{feature_name}'. \"\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f\"Feature '{feature_name}' not found in label encodings.\")\n",
    "        return updated_features\n",
    "    \n",
    "    def convert_static_inputs(self, static_inputs):\n",
    "        with open('c:\\\\Users\\\\ziming4\\\\OneDrive - University of Alberta\\\\Porject_OPI\\\\WebPrototype0823\\\\OpenPredictionInterface\\\\backend\\\\app/integrations/Montney/label_encodings.pkl', 'rb') as file:\n",
    "            label_encodings = pickle.load(file)\n",
    "        feature_names = ['ENVInterval', 'County', 'ENVOperator','WellPadDirection'] \n",
    "        for feat_name in feature_names:\n",
    "            try:\n",
    "                static_inputs = self.classify_and_update_feature(feat_name, static_inputs, label_encodings)\n",
    "            except ValueError as e:\n",
    "                print(f\"Warning: {e}\")\n",
    "                \n",
    "        return static_inputs\n",
    "\n",
    "    def predict_peak(self):\n",
    "        peak_inputs = {key: self.static_inputs[key] for key in self.peak_input_keys}\n",
    "        p_inputs = pd.DataFrame([peak_inputs])\n",
    "        peaks = self.gbr_model_p.predict(p_inputs)\n",
    "        self.static_inputs['PeakTime'] = peaks[0][0]\n",
    "        self.static_inputs['PeakRate'] = peaks[0][1]\n",
    "\n",
    "    def create_dynamic_df(self):\n",
    "        start_year = int(self.static_inputs['StartYear'])\n",
    "        start_month = int(self.static_inputs.get('Month', 1))  # Use January (1) as default if 'Month' is missing\n",
    "        start_date = datetime(start_year, start_month, 1)\n",
    "        date_list = [start_date + relativedelta(months=+i) for i in range(60)]\n",
    "\n",
    "        self.dynamic_df = pd.DataFrame({\n",
    "            'TotalProdMonths': list(range(1, 61)),\n",
    "            'Year': [date.year for date in date_list],\n",
    "            'Month': [date.month for date in date_list],\n",
    "            'ShutIns': self.shut_ins.flatten()\n",
    "        })\n",
    "\n",
    "    def predict_profile(self):\n",
    "        if not self.static_inputs or self.dynamic_df is None:\n",
    "            raise ValueError(\"Static inputs must be set, and dynamic inputs must be generated before prediction.\")\n",
    "\n",
    "        # Prepare dynamic and static inputs\n",
    "        dynamic_inputs = self.dynamic_df[['TotalProdMonths', 'Year', 'Month', 'ShutIns']].values\n",
    "        if self.hist_len == 0:\n",
    "            self.hist_len = 1 \n",
    "\n",
    "        # Encoder input preparation\n",
    "        encoder_inputs = np.concatenate((dynamic_inputs, self.prod_hist), axis=1)\n",
    "        encoder_inputs_scaled = self.scalers['scaler_encoder'].transform(encoder_inputs.reshape(-1, 7)).reshape(1, 60, 7)\n",
    "        encoder_inputs_scaled[:, self.hist_len:, :] = -1e9  # Apply mask beyond the history length\n",
    "\n",
    "        # Decoder D inputs preparation\n",
    "        decoder_D_inputs_scaled = self.scalers['scaler_decoder_D'].transform(dynamic_inputs.reshape(-1, 4)).reshape(1, 60, 4)\n",
    "        decoder_D_inputs_scaled[:, :self.hist_len, :] = -1e9  # Apply mask up to history length\n",
    "        \n",
    "        # Decoder S inputs preparation\n",
    "        NN_static_inputs = {key: self.static_inputs[key] for key in self.peak_input_keys + ['PeakTime', 'PeakRate']}\n",
    "        decoder_S_inputs = np.array(list(NN_static_inputs.values()), dtype='float32').reshape(1, -1)\n",
    "        decoder_S_inputs_scaled = self.scalers['scaler_decoder_S'].transform(decoder_S_inputs)\n",
    "\n",
    "        # Predict the profile\n",
    "        y_pred = self.AI_model.predict([encoder_inputs_scaled, decoder_D_inputs_scaled, decoder_S_inputs_scaled])\n",
    "        y_pred[:, 0, :] = 0  # Change the first timestep as zero\n",
    "        y_pred_restored = self.scalers['scaler_y_pred'].inverse_transform(y_pred.reshape(-1, 3)).reshape(1, 60, 3)\n",
    "        y_pred_restored[:, :self.hist_len, :] = self.prod_hist[:self.hist_len, :]\n",
    "        \n",
    "        return y_pred_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def Montney_pred_MED(static_inputs):\n",
    "    \"\"\"\n",
    "    Production forecasting for Central Montney using a deep learning model.\n",
    "    - 'static_inputs' (dic): File name. Either user inputs or according to the related chat history.\n",
    "    - 'prod_hist' (list): Production history data. Defaults to None if not provided or empty list.\n",
    "    - 'shut_list' (list): Shut-in periods. Defaults to None if not provided or empty list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define required static input keys\n",
    "    static_input_keys = [\n",
    "        'Longitude', 'Latitude', 'ENVInterval', 'StartYear', 'County', 'ElevationGL_FT',\n",
    "        'TotalOrganicCarbon_WTPCT', 'HeightOfHCPV_FT', 'HCPV_PCT', 'PhiH_FT',\n",
    "        'WaterSaturation_PCT', 'NonClayVolume_PCT', 'ClayVolume_PCT',\n",
    "        'EffectivePorosity_PCT', 'DensityPorosity_PCT', 'Resistivity_OHMSM',\n",
    "        'BulkDensity_GPerCC', 'GammaRay_API', 'Isopach_FT', 'SubseaBaseDepth_FT',\n",
    "        'SubseaTopDepth_FT', 'BottomOfZone_FT', 'TopOfZone_FT', 'GasGravity_SG',\n",
    "        'ENVOperator', 'WellPadDirection', 'AverageStageSpacing_FT', 'FracStages',\n",
    "        'CompletionTime_DAYS', 'LateralLength_FT', 'MD_FT', 'TVD_FT'\n",
    "    ]\n",
    "\n",
    "    # Check for missing static inputs\n",
    "    missing_keys = [key for key in static_input_keys if key not in static_inputs or static_inputs[key] is None]\n",
    "    \n",
    "    if missing_keys:\n",
    "        return json.dumps({\n",
    "            \"error\": f\"Missing required static inputs: {', '.join(missing_keys)}\",\n",
    "            \"message for python_repl\": \"There is an error. Do not generate any plots.\"\n",
    "        })\n",
    "\n",
    "    # Ensure 'Month' key exists in static_inputs, defaulting to 1 if not present\n",
    "    static_inputs.setdefault('Month', 1)\n",
    "\n",
    "    # Initialize the model with the given inputs\n",
    "    model = CentralMontneyRatePred(static_inputs, static_input_keys, prod_hist=None, shut_list=None)\n",
    "\n",
    "    # Generate the dynamic inputs\n",
    "    model.create_dynamic_df()\n",
    "\n",
    "    # Predict the production profile\n",
    "    profile = model.predict_profile() #[1,60,1]\n",
    "\n",
    "    # Prepare the final results\n",
    "    output_results = {}\n",
    "\n",
    "    output_results['gas_rate']= profile[0,:,0].tolist() #  gas\n",
    "    output_results['oil_rate']= profile[0,:,1].tolist() #  oil \n",
    "    output_results['water_rate']= profile[0,:,2].tolist() # water\n",
    "    # return json.dumps(output_results)\n",
    "    return output_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ziming4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ziming4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ziming4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ziming4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 939ms/step\n",
      "[0.0, 899.7792358398438, 1201.938720703125, 1282.2681884765625, 1235.5023193359375, 1146.595947265625, 1063.169189453125, 993.8115234375, 936.3875122070312, 888.0675659179688, 846.8330078125, 811.2733154296875, 778.4771728515625, 762.7698364257812, 736.1774291992188, 706.9515380859375, 678.9669189453125, 653.671630859375, 631.2133178710938, 611.3226318359375, 593.6499633789062, 577.8733520507812, 563.7200317382812, 550.9564819335938, 537.2736206054688, 534.3765869140625, 524.1363525390625, 511.3260192871094, 498.3046875, 486.1567077636719, 475.13067626953125, 465.17156982421875, 456.1492004394531, 447.934326171875, 440.4193115234375, 433.50823974609375, 424.813720703125, 424.6185302734375, 418.8636169433594, 411.00909423828125, 402.76837158203125, 394.9989318847656, 387.9043273925781, 381.4578857421875, 375.5753479003906, 370.1707763671875, 365.1707763671875, 360.5252990722656, 353.93206787109375, 354.4033508300781, 350.43438720703125, 344.7820739746094, 338.7802429199219, 333.12542724609375, 327.9811096191406, 323.31396484375, 319.04718017578125, 315.1141052246094, 311.45794677734375, 308.043701171875]\n",
      "[0.0, 104.8586654663086, 344.489990234375, 534.9915771484375, 554.283447265625, 494.030029296875, 428.19732666015625, 374.6012268066406, 332.71002197265625, 299.5335388183594, 272.7663879394531, 250.83738708496094, 233.01467895507812, 218.33285522460938, 202.26995849609375, 188.12913513183594, 175.32589721679688, 163.67898559570312, 153.240478515625, 144.0430145263672, 136.03468322753906, 129.10362243652344, 123.11448669433594, 117.93036651611328, 113.7023696899414, 110.1139907836914, 105.29025268554688, 100.90074157714844, 96.69033813476562, 92.65023803710938, 88.88105773925781, 85.467529296875, 82.43925476074219, 79.78572845458984, 77.47442626953125, 75.46440124511719, 74.0372543334961, 72.77806091308594, 70.5728530883789, 68.50911712646484, 66.42845153808594, 64.35885620117188, 62.39109802246094, 60.59553909301758, 59.002723693847656, 57.61378479003906, 56.41331100463867, 55.38002395629883, 54.841487884521484, 54.29217529296875, 52.99675750732422, 51.75722885131836, 50.45916748046875, 49.14190673828125, 47.88346481323242, 46.74086380004883, 45.737361907958984, 44.873817443847656, 44.13982009887695, 43.52024459838867]\n",
      "[0.0, 42.09703826904297, 54.428009033203125, 53.553462982177734, 45.540428161621094, 37.459617614746094, 31.680891036987305, 27.767602920532227, 24.993236541748047, 22.890729904174805, 21.210805892944336, 19.820985794067383, 19.067249298095703, 18.452255249023438, 17.572887420654297, 16.748493194580078, 15.966863632202148, 15.219480514526367, 14.512967109680176, 13.856291770935059, 13.25418472290039, 12.706962585449219, 12.211786270141602, 11.764690399169922, 11.651226043701172, 11.540781021118164, 11.238962173461914, 10.93826961517334, 10.63122272491455, 10.316606521606445, 10.002845764160156, 9.69868278503418, 9.41042709350586, 9.140961647033691, 8.891368865966797, 8.661331176757812, 8.676382064819336, 8.671154975891113, 8.518036842346191, 8.358745574951172, 8.186838150024414, 8.003349304199219, 7.8150835037231445, 7.628846168518066, 7.449908256530762, 7.280838966369629, 7.122539520263672, 6.975685119628906, 7.027280330657959, 7.05053186416626, 6.953425407409668, 6.8499650955200195, 6.734428405761719, 6.608482360839844, 6.4775800704956055, 6.347308158874512, 6.221497535705566, 6.102130889892578, 5.990199089050293, 5.886107444763184]\n"
     ]
    }
   ],
   "source": [
    "inputs = {'Longitude': -120.37108, 'Latitude': 55.962475, 'ENVInterval': \"LOWER MONTNEY A\", 'StartYear': 2015, 'Month': 1,\n",
    "           'County': \"SALT CREEK\", 'ElevationGL_FT': 2326.4050715475264, 'TotalOrganicCarbon_WTPCT': 2.201066488726354,\n",
    "             'HeightOfHCPV_FT': 8.808171558963744, 'HCPV_PCT': 0.04914084647439048, 'PhiH_FT': 10.57039430708461,\n",
    "               'WaterSaturation_PCT': 0.14695686332702404, 'NonClayVolume_PCT': 0.8893624230966368, 'ClayVolume_PCT': 0.05920733462785699,\n",
    "                 'EffectivePorosity_PCT': 0.061576428149606774, 'DensityPorosity_PCT': 0.06691177902845037, 'Resistivity_OHMSM': 88.48815046925344,\n",
    "                   'BulkDensity_GPerCC': 2.5971327125627113, 'GammaRay_API': 130.2878673089267, 'Isopach_FT': 175.2161426462049,\n",
    "                     'SubseaBaseDepth_FT': -4842.154247107849, 'SubseaTopDepth_FT': -4654.953653646224, 'BottomOfZone_FT': 7041.939095090544,\n",
    "                       'TopOfZone_FT': 6862.18474457186, 'GasGravity_SG': 0.7021147491786565, 'ENVOperator': \"CENOVUS\", 'WellPadDirection':\"E\",\n",
    "                         'AverageStageSpacing_FT': 500, 'FracStages': 20,'CompletionTime_DAYS': 20,\n",
    "                           'LateralLength_FT': 1000, 'MD_FT': 10000, 'TVD_FT': 2000}\n",
    "\n",
    "y_pred = Montney_pred_MED(static_inputs = inputs)\n",
    "# y_pred = Montney_pred_MED(static_inputs = inputs, shut_list = [15,16,56,57,58])\n",
    "\n",
    "print(y_pred['gas_rate'])\n",
    "print(y_pred['oil_rate'])\n",
    "print(y_pred['water_rate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
